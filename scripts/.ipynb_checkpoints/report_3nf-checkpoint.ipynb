{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1109e1c1",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1611a",
   "metadata": {},
   "source": [
    "## Connect to PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection parameters\n",
    "DB_PASSWORD = \"tiger\"\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'ds_jobs',\n",
    "    'user': 'postgres',\n",
    "    'password': DB_PASSWORD,\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "# Create SQLAlchemy engine for pandas integration\n",
    "engine = create_engine(f'postgresql://{DB_CONFIG[\"user\"]}:{DB_CONFIG[\"password\"]}@{DB_CONFIG[\"host\"]}:{DB_CONFIG[\"port\"]}/{DB_CONFIG[\"dbname\"]}')\n",
    "\n",
    "# Create psycopg2 connection\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "print(\"‚úì Database connection successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaebdd4",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "### First 5 rows of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from tables\n",
    "jobpostings = pd.read_sql(\"SELECT * FROM jobpostings LIMIT 5;\", engine)\n",
    "skills_table = pd.read_sql(\"SELECT * FROM skills_table LIMIT 5;\", engine)\n",
    "skill_categories = pd.read_sql(\"SELECT * FROM skill_categories LIMIT 5;\", engine)\n",
    "job_skill_mapping = pd.read_sql(\"SELECT * FROM job_skill_mapping LIMIT 5;\", engine)\n",
    "\n",
    "print(\"\\n=== Job Postings ===\")\n",
    "display(jobpostings)\n",
    "\n",
    "print(\"\\n=== Skills Table ===\")\n",
    "display(skills_table)\n",
    "\n",
    "print(\"\\n=== Skill Categories ===\")\n",
    "display(skill_categories)\n",
    "\n",
    "print(\"\\n=== Job-Skill Mapping ===\")\n",
    "display(job_skill_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559ac32",
   "metadata": {},
   "source": [
    "### Column Types and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobpostings_full = pd.read_sql(\"SELECT * FROM jobpostings;\", engine)\n",
    "print(jobpostings_full.info())\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"Job Postings: {jobpostings_full.shape}\")\n",
    "print(f\"Skills: {pd.read_sql('SELECT COUNT(*) as count FROM skills_table', engine)['count'][0]} rows\")\n",
    "print(f\"Skill Categories: {pd.read_sql('SELECT COUNT(*) as count FROM skill_categories', engine)['count'][0]} rows\")\n",
    "print(f\"Job-Skill Mappings: {pd.read_sql('SELECT COUNT(*) as count FROM job_skill_mapping', engine)['count'][0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3427380",
   "metadata": {},
   "source": [
    "---\n",
    "# 5 Questions Answered\n",
    "\n",
    "Each question is answered by querying data from the PostgreSQL database with joins across multiple normalized tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a17cc",
   "metadata": {},
   "source": [
    "## Q1. What are the main technologies?\n",
    "\n",
    "### Top 20 Most In-Demand Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH SkillCount AS (\n",
    "    SELECT st.skill,\n",
    "    COUNT(jsm.jobid) AS job_count\n",
    "    FROM job_skill_mapping jsm\n",
    "    JOIN skills_table st ON jsm.skill_id = st.skill_id\n",
    "    GROUP BY st.skill\n",
    ")\n",
    "SELECT skill, job_count\n",
    "FROM SkillCount\n",
    "ORDER BY job_count DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "\n",
    "top20_skills = pd.read_sql(query, engine)\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bars = ax.barh(top20_skills['skill'], top20_skills['job_count'], color='firebrick')\n",
    "ax.set_xlabel('Frequency', fontsize=12)\n",
    "ax.set_ylabel('Skill', fontsize=12)\n",
    "ax.set_title('Top 20 Skills', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, (skill, count) in enumerate(zip(top20_skills['skill'], top20_skills['job_count'])):\n",
    "    ax.text(count + 100, i, str(count), va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/top20_skills.png', dpi=400, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "display(top20_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06402da4",
   "metadata": {},
   "source": [
    "### Top 10 Skills by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH SkillCount AS (\n",
    "    SELECT sc.skill_category, st.skill,\n",
    "    COUNT(jsm.jobid) AS job_count\n",
    "    FROM job_skill_mapping jsm\n",
    "    JOIN skills_table st ON jsm.skill_id = st.skill_id\n",
    "    JOIN skill_categories sc ON st.skill_id = sc.skill_id\n",
    "    GROUP BY sc.skill_category, st.skill\n",
    "), \n",
    "RankedSkills AS (\n",
    "    SELECT skill_category, skill, job_count,\n",
    "    RANK() OVER (PARTITION BY skill_category ORDER BY job_count DESC) AS rank\n",
    "    FROM SkillCount\n",
    ")\n",
    "SELECT skill_category, skill, job_count\n",
    "FROM RankedSkills\n",
    "WHERE rank <= 10\n",
    "ORDER BY skill_category, rank;\n",
    "\"\"\"\n",
    "\n",
    "top10_by_cat = pd.read_sql(query, engine)\n",
    "\n",
    "# Get unique categories\n",
    "categories = top10_by_cat['skill_category'].unique()\n",
    "n_categories = len(categories)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=(n_categories + 1) // 2, ncols=2, figsize=(14, 5 * ((n_categories + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = cm.tab10(range(n_categories))\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    cat_data = top10_by_cat[top10_by_cat['skill_category'] == category].sort_values('job_count', ascending=True)\n",
    "    \n",
    "    axes[idx].barh(cat_data['skill'], cat_data['job_count'], color=colors[idx])\n",
    "    axes[idx].set_xlabel('Count', fontsize=10)\n",
    "    axes[idx].set_title(f'{category}', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (skill, count) in enumerate(zip(cat_data['skill'], cat_data['job_count'])):\n",
    "        axes[idx].text(count + 50, i, str(count), va='center', fontsize=8)\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(n_categories, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Top 10 Skills by Skill Category', fontsize=16, fontweight='bold', y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/top10_skill_cat.png', dpi=400, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab35e8",
   "metadata": {},
   "source": [
    "## Q2. What is the median salary for each job title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b982c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT job_title_short, salary_year_avg FROM jobpostings;\"\n",
    "salary_data = pd.read_sql(query, engine)\n",
    "\n",
    "# Calculate median salary by job title\n",
    "median_salaries = salary_data.groupby('job_title_short')['salary_year_avg'].median().reset_index()\n",
    "median_salaries.columns = ['job_title_short', 'med_salary']\n",
    "median_salaries = median_salaries.sort_values('med_salary', ascending=False)\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(median_salaries['job_title_short'], median_salaries['med_salary'], color='firebrick')\n",
    "ax.set_xlabel('Median Salary (USD)', fontsize=12)\n",
    "ax.set_ylabel('Job Title', fontsize=12)\n",
    "ax.set_title('Median Salary for Each Role', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Format x-axis as currency\n",
    "formatter = FuncFormatter(lambda x, pos: f'${x/1000:.0f}K')\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Add value labels\n",
    "for i, (title, salary) in enumerate(zip(median_salaries['job_title_short'], median_salaries['med_salary'])):\n",
    "    ax.text(salary + 1000, i, f'${salary:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/med_salary_role.png', dpi=400, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "display(median_salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c99bbb",
   "metadata": {},
   "source": [
    "### Top 20 Skills by Median Salary (by Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT sc.skill_category, st.skill, jp.salary_year_avg\n",
    "FROM job_skill_mapping jsm\n",
    "JOIN skills_table st ON jsm.skill_id = st.skill_id\n",
    "JOIN skill_categories sc ON st.skill_id = sc.skill_id\n",
    "JOIN jobpostings jp ON jsm.jobid = jp.jobid;\n",
    "\"\"\"\n",
    "\n",
    "skill_salaries = pd.read_sql(query, engine)\n",
    "\n",
    "# Calculate statistics\n",
    "skill_stats = skill_salaries.groupby(['skill_category', 'skill']).agg(\n",
    "    med_salary=('salary_year_avg', 'median'),\n",
    "    n=('salary_year_avg', 'count'),\n",
    "    max_salary=('salary_year_avg', 'max'),\n",
    "    min_salary=('salary_year_avg', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Filter skills with at least 50 job postings\n",
    "skill_stats = skill_stats[skill_stats['n'] >= 50]\n",
    "\n",
    "# Get top 20 skills per category\n",
    "top20_per_cat = skill_stats.groupby('skill_category').apply(\n",
    "    lambda x: x.nlargest(20, 'med_salary')\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Create subplots\n",
    "categories = top20_per_cat['skill_category'].unique()\n",
    "n_categories = len(categories)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=(n_categories + 1) // 2, ncols=2, figsize=(16, 6 * ((n_categories + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = cm.tab10(range(n_categories))\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    cat_data = top20_per_cat[top20_per_cat['skill_category'] == category].sort_values('med_salary', ascending=True)\n",
    "    \n",
    "    axes[idx].barh(cat_data['skill'], cat_data['med_salary'], color=colors[idx])\n",
    "    axes[idx].set_xlabel('Median Salary (USD)', fontsize=10)\n",
    "    axes[idx].set_title(f'{category}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlim(70000, 185000)\n",
    "    formatter = FuncFormatter(lambda x, pos: f'${x/1000:.0f}K')\n",
    "    axes[idx].xaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (skill, salary) in enumerate(zip(cat_data['skill'], cat_data['med_salary'])):\n",
    "        axes[idx].text(salary + 1500, i, f'${salary:,.0f}', va='center', fontsize=7)\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(n_categories, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Top 20 Skills by Median Salary per Category', fontsize=16, fontweight='bold', y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/top20skill_salary_cat.png', dpi=400, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ec2c2",
   "metadata": {},
   "source": [
    "## Q3. Which industry field is asking for these roles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fe9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT industry FROM jobpostings WHERE industry IS NOT NULL;\"\n",
    "industry_data = pd.read_sql(query, engine)\n",
    "\n",
    "# Count by industry\n",
    "industry_counts = industry_data['industry'].value_counts().reset_index()\n",
    "industry_counts.columns = ['industry', 'Count']\n",
    "\n",
    "print(f\"\\nTotal industries: {len(industry_counts)}\")\n",
    "print(f\"\\nTop 20 Industries by Job Postings:\")\n",
    "display(industry_counts.head(20))\n",
    "\n",
    "# Interactive table (if running in Jupyter)\n",
    "display(industry_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd7344",
   "metadata": {},
   "source": [
    "## Q4. What is the relation of location with respect to job postings and salary?\n",
    "\n",
    "Analyzing Data Scientist salaries across US cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0379762",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT job_location, salary_year_avg \n",
    "FROM jobpostings\n",
    "WHERE job_country = 'United States' AND job_title_short = 'Data Scientist';\n",
    "\"\"\"\n",
    "\n",
    "location_data = pd.read_sql(query, engine)\n",
    "\n",
    "# Extract city (first part before comma)\n",
    "location_data['city'] = location_data['job_location'].str.split(',').str[0]\n",
    "\n",
    "# Calculate stats by city\n",
    "city_stats = location_data.groupby('city').agg(\n",
    "    n=('salary_year_avg', 'count'),\n",
    "    med_salary=('salary_year_avg', 'median')\n",
    ").reset_index()\n",
    "\n",
    "# Filter cities with at least 10 postings\n",
    "city_stats = city_stats[city_stats['n'] >= 10]\n",
    "\n",
    "# Remove non-specific locations\n",
    "exclude_cities = ['Toronto', 'United States', 'Anywhere', 'California']\n",
    "city_stats = city_stats[~city_stats['city'].isin(exclude_cities)]\n",
    "\n",
    "city_stats = city_stats.sort_values('med_salary', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Cities by Median Salary for Data Scientists:\")\n",
    "display(city_stats.head(15))\n",
    "\n",
    "# Note: For map visualization, you'd need geocoding (lat/lon coordinates)\n",
    "# The original R script uses tidygeocoder. In Python, you can use geopy or saved coordinates\n",
    "print(\"\\nüìç For geographic visualization, geocoding coordinates would be needed.\")\n",
    "print(\"The original creates a US map with city markers sized by job count and colored by salary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f827e61",
   "metadata": {},
   "source": [
    "## Q5. Does remote/work from home give lower pay than onsite?\n",
    "\n",
    "Comparing remote vs onsite salaries for Full-time US jobs by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a30d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get onsite jobs\n",
    "query_onsite = \"\"\"\n",
    "SELECT job_title_short, job_location, search_location, salary_year_avg \n",
    "FROM jobpostings\n",
    "WHERE job_work_from_home = FALSE \n",
    "    AND job_country = 'United States' \n",
    "    AND job_schedule_type = 'Full-time';\n",
    "\"\"\"\n",
    "\n",
    "onsite = pd.read_sql(query_onsite, engine)\n",
    "\n",
    "# Extract state from location\n",
    "onsite['state'] = onsite['job_location'].str.split(',').str[-1].str.strip()\n",
    "onsite['state'] = onsite['state'].str.replace(r'\\s*\\(.*?\\)', '', regex=True)\n",
    "\n",
    "# Normalize state abbreviations\n",
    "state_mapping = {\n",
    "    'NY': 'New York',\n",
    "    'GA': 'Georgia',\n",
    "    'FL': 'Florida',\n",
    "    'IL': 'Illinois',\n",
    "    'CA': 'California',\n",
    "    'TX': 'Texas'\n",
    "}\n",
    "onsite['state'] = onsite['state'].replace(state_mapping)\n",
    "\n",
    "onsite_agg = onsite.groupby(['state', 'job_title_short']).agg(\n",
    "    n=('salary_year_avg', 'count'),\n",
    "    med_salary=('salary_year_avg', 'median')\n",
    ").reset_index()\n",
    "\n",
    "# Get remote jobs\n",
    "query_remote = \"\"\"\n",
    "SELECT job_title_short, job_location, search_location, salary_year_avg \n",
    "FROM jobpostings\n",
    "WHERE job_work_from_home = TRUE \n",
    "    AND job_country = 'United States' \n",
    "    AND job_schedule_type = 'Full-time';\n",
    "\"\"\"\n",
    "\n",
    "remote = pd.read_sql(query_remote, engine)\n",
    "\n",
    "# Extract state from search location\n",
    "remote['state'] = remote['search_location'].str.split(',').str[0]\n",
    "\n",
    "remote_agg = remote.groupby(['state', 'job_title_short']).agg(\n",
    "    n=('salary_year_avg', 'count'),\n",
    "    med_salary=('salary_year_avg', 'median')\n",
    ").reset_index()\n",
    "\n",
    "# Define states and jobs to compare\n",
    "states = ['California', 'Florida', 'Georgia', 'Illinois', 'New York', 'Texas']\n",
    "jobs = ['Business Analyst', 'Data Analyst', 'Data Engineer', 'Data Scientist', \n",
    "        'Machine Learning Engineer', 'Senior Data Analyst', 'Senior Data Engineer', \n",
    "        'Senior Data Scientist', 'Software Engineer']\n",
    "\n",
    "# Create comparison dataframe\n",
    "diff_data = []\n",
    "\n",
    "for state in states:\n",
    "    remote_state = remote_agg[remote_agg['state'] == state]\n",
    "    onsite_state = onsite_agg[onsite_agg['state'] == state]\n",
    "    \n",
    "    merged = pd.merge(remote_state, onsite_state, \n",
    "                     on='job_title_short', \n",
    "                     suffixes=('_remote', '_onsite'))\n",
    "    \n",
    "    merged['diff_pct'] = ((merged['med_salary_remote'] - merged['med_salary_onsite']) / \n",
    "                          merged['med_salary_onsite'])\n",
    "    \n",
    "    for _, row in merged.iterrows():\n",
    "        diff_data.append({\n",
    "            'job': row['job_title_short'],\n",
    "            'state': state,\n",
    "            'diff_pct': row['diff_pct']\n",
    "        })\n",
    "\n",
    "diff_df = pd.DataFrame(diff_data)\n",
    "\n",
    "# Pivot for display\n",
    "diff_pivot = diff_df.pivot(index='job', columns='state', values='diff_pct')\n",
    "\n",
    "print(\"\\nRemote vs On-Site Salary Difference (%)\")\n",
    "print(\"Positive values = Remote pays MORE, Negative values = Remote pays LESS\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Format as percentage\n",
    "display(diff_pivot.style.format(\"{:.1%}\").background_gradient(cmap='RdYlGn', axis=None))\n",
    "\n",
    "print(\"\\n‚úì Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c585d",
   "metadata": {},
   "source": [
    "## Close Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
